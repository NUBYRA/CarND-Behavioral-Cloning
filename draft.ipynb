{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Lambda, Conv2D, Flatten, Dense\n",
    "from  keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "filepath = 'data/driving_log.csv'\n",
    "image_height, image_width, image_depth = 66, 200, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(data_dir, image_path):\n",
    "    return mpimg.imread(os.path.join(data_dir,image_path.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_image(image):\n",
    "    return image[80:140, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_image(image):\n",
    "    return cv2.resize(image, (image_width, image_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb2yuv(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_preprocess(image):\n",
    "    img = crop_image(image)\n",
    "    img = resize_image(img)\n",
    "    img = rgb2yuv(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_image(data_dir, image_paths):\n",
    "    correction = 0.25\n",
    "    choice = np.random.choice(3)\n",
    "    if choice == 0:\n",
    "        return load_image(data_dir, image_paths['left']), image_paths['steering'] + correction\n",
    "    elif choice == 1:\n",
    "        return load_image(data_dir, image_paths['right']), image_paths['steering'] - correction\n",
    "    return load_image(data_dir, image_paths['center']), image_paths['steering']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_flip(image, steering):\n",
    "    if np.random.rand() < .5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        steering = -steering \n",
    "    return image, steering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_brightness(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    random_bright = .5+np.random.uniform()\n",
    "    image[:,:,2] = image[:,:,2]*random_bright\n",
    "    image[:,:,2][image[:,:,2]>255]  = 255\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_translation(image, steering, range_x, range_y):\n",
    "    translation_x = range_x*(np.random.uniform() - .5)\n",
    "    translation_y = range_y*(np.random.uniform() - .5)\n",
    "    steering = steering + translation_x*.002\n",
    "    Trans_M = np.float32([[1,0,translation_x],[0,1,translation_y]])\n",
    "    height, width = image.shape[:2]\n",
    "    image = cv2.warpAffine(image, Trans_M, (width, height))\n",
    "    return image, steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_shadow(image):\n",
    "    brightness = 0.5\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    x = random.randint(0, image.shape[1])\n",
    "    y = random.randint(0, image.shape[0])\n",
    "    width = random.randint(0, image.shape[1]) * random.randint(2, 10)\n",
    "    height = random.randint(0, image.shape[0]) * random.randint(2, 10)\n",
    "    image[y:y+height,x:x+width,1] = image[y:y+height,x:x+width,1]*brightness\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_HLS2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_shear(image, steering_angle):\n",
    "    # Source: https://medium.com/@ksakmann/behavioral-cloning-make-a-car-drive-like-yourself-dc6021152713#.7k8vfppvk\n",
    "    shear_range = 200\n",
    "    rows, cols, ch = image.shape\n",
    "    dx = np.random.randint(-shear_range, shear_range + 1)\n",
    "    random_point = [cols / 2 + dx, rows / 2]\n",
    "    pts1 = np.float32([[0, rows], [cols, rows], [cols / 2, rows / 2]])\n",
    "    pts2 = np.float32([[0, rows], [cols, rows], random_point])\n",
    "    dsteering = dx / (rows / 2) * 360 / (2 * np.pi * 25.0) / 6.0\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "    image = cv2.warpAffine(image, M, (cols, rows), borderMode=1)\n",
    "    steering_angle += dsteering\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_augmentation(data_dir, image_paths, range_x, range_y):\n",
    "    image, steering  = random_image(data_dir, image_paths)\n",
    "    if np.random.choice(2) == 1:\n",
    "        image, steering = random_shear(image, steering)\n",
    "    image, steering = random_flip(image, steering)\n",
    "    image, steering = random_translation(image, steering, range_x, range_y)\n",
    "    image = random_shadow(image)\n",
    "    image = random_brightness(image)\n",
    "    return image, steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(data_dir, sample, batch_size, is_training):\n",
    "    images = np.empty([batch_size, image_height, image_width, image_depth])\n",
    "    steers = np.empty(batch_size)\n",
    "    while True:\n",
    "        i = 0\n",
    "        for index in np.random.permutation(sample.shape[0]):\n",
    "            image_paths = sample.loc[index]\n",
    "            steering = sample.loc[index]['steering']\n",
    "            if is_training and np.random.rand() < 0.6:\n",
    "                image, steering = image_augmentation(data_dir, image_paths, 100, 10)\n",
    "            else:\n",
    "                image = load_image(data_dir, image_paths['center']) \n",
    "            images[i] = image_preprocess(image)\n",
    "            steers[i] = steering\n",
    "            i = i + 1\n",
    "            if i == batch_size:\n",
    "                break \n",
    "        yield images, steers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_valid(filepath): \n",
    "    valid_size = .1\n",
    "    data = pd.read_csv(filepath)\n",
    "    X_data = data[[\"center\", \"left\", \"right\"]]\n",
    "    y_data = data['steering']\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_data, y_data, test_size = valid_size)\n",
    "    train = X_train.assign(steering = y_train)\n",
    "    train = train.reset_index()\n",
    "    valid = X_valid.assign(steering = y_valid)\n",
    "    valid = valid.reset_index()\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NVIDIA():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5-1.0, input_shape = (image_height, image_width, image_depth)))\n",
    "    model.add(Conv2D(24, (5, 5), strides=(2,2), activation='relu'))\n",
    "    model.add(Conv2D(36, (5, 5), strides=(2,2), activation='relu'))\n",
    "    model.add(Conv2D(48, (5, 5), strides=(2,2), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(data_dir, filepath, batch_size):\n",
    "    train, valid = create_train_valid(filepath)\n",
    "    model = NVIDIA()\n",
    "    checkpoint = ModelCheckpoint('model.h5', monitor = 'val_loss', verbose = 0, save_best_only = True, mode='auto')\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(lr = 1.0e-4))\n",
    "    train_generator = batch_generator(data_dir, train, batch_size, True)\n",
    "    validation_generator = batch_generator(data_dir, valid, batch_size, False)\n",
    "    model.fit_generator(train_generator, \n",
    "                    steps_per_epoch = 10000, \n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = len(valid), \n",
    "                    epochs = 3,\n",
    "                    callbacks =[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 66, 200, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 98, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 47, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 22, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 20, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 18, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "10000/10000 [==============================] - 2544s - loss: 0.0313 - val_loss: 0.0089\n",
      "Epoch 2/3\n",
      "10000/10000 [==============================] - 2539s - loss: 0.0227 - val_loss: 0.0089\n",
      "Epoch 3/3\n",
      "10000/10000 [==============================] - 2540s - loss: 0.0197 - val_loss: 0.0100\n"
     ]
    }
   ],
   "source": [
    "train_model(data_dir, filepath, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
